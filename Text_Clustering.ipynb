{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from sklearn.cluster import KMeans\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the reviews from the original text file and making a list of stopwords as per the instructions.\n",
    "\n",
    "reviews=[]\n",
    "L=[]\n",
    "long_list=\"a<br>able<br>about<br>above<br>abst<br>accordance<br>according<br>accordingly<br>across<br>act<br>actually<br>added<br>adj<br>affected<br>affecting<br>affects<br>after<br>afterwards<br>again<br>against<br>ah<br>all<br>almost<br>alone<br>along<br>already<br>also<br>although<br>always<br>am<br>among<br>amongst<br>an<br>and<br>announce<br>another<br>any<br>anybody<br>anyhow<br>anymore<br>anyone<br>anything<br>anyway<br>anyways<br>anywhere<br>apparently<br>approximately<br>are<br>aren<br>don>won<br>arent<br>arise<br>around<br>as<br>aside<br>ask<br>asking<br>at<br>auth<br>available<br>away<br>awfully<br>b<br>back<br>be<br>became<br>because<br>become<br>becomes<br>becoming<br>been<br>before<br>beforehand<br>begin<br>beginning<br>beginnings<br>begins<br>behind<br>being<br>believe<br>below<br>beside<br>besides<br>between<br>beyond<br>biol<br>both<br>brief<br>briefly<br>but<br>by<br>c<br>ca<br>came<br>can<br>cannot<br>can't<br>cause<br>causes<br>certain<br>certainly<br>co<br>com<br>come<br>comes<br>contain<br>containing<br>contains<br>could<br>couldnt<br>d<br>date<br>did<br>didn't<br>different<br>do<br>does<br>doesn't<br>doing<br>done<br>don't<br>down<br>downwards<br>due<br>during<br>e<br>each<br>ed<br>edu<br>effect<br>eg<br>eight<br>eighty<br>either<br>else<br>elsewhere<br>end<br>ending<br>enough<br>especially<br>et<br>et-al<br>etc<br>even<br>ever<br>every<br>everybody<br>everyone<br>everything<br>everywhere<br>ex<br>except<br>f<br>far<br>few<br>ff<br>fifth<br>first<br>five<br>fix<br>followed<br>following<br>follows<br>for<br>former<br>formerly<br>forth<br>found<br>four<br>from<br>further<br>furthermore<br>g<br>gave<br>get<br>gets<br>getting<br>give<br>given<br>gives<br>giving<br>go<br>goes<br>gone<br>got<br>gotten<br>h<br>had<br>happens<br>hardly<br>has<br>hasn't<br>have<br>haven't<br>having<br>he<br>hed<br>hence<br>her<br>here<br>hereafter<br>hereby<br>herein<br>heres<br>hereupon<br>hers<br>herself<br>hes<br>hi<br>hid<br>him<br>himself<br>his<br>hither<br>home<br>how<br>howbeit<br>however<br>hundred<br>i<br>id<br>ie<br>if<br>i'll<br>im<br>immediate<br>immediately<br>importance<br>important<br>in<br>inc<br>indeed<br>index<br>information<br>instead<br>into<br>invention<br>inward<br>is<br>isn't<br>it<br>itd<br>it'll<br>its<br>itself<br>i've<br>j<br>just<br>k<br>keep<br>keeps<br>kept<br>kg<br>km<br>know<br>known<br>knows<br>l<br>largely<br>last<br>lately<br>later<br>latter<br>latterly<br>least<br>less<br>lest<br>let<br>lets<br>like<br>liked<br>likely<br>line<br>little<br>'ll<br>look<br>looking<br>looks<br>ltd<br>m<br>made<br>mainly<br>make<br>makes<br>many<br>may<br>maybe<br>me<br>mean<br>means<br>meantime<br>meanwhile<br>merely<br>mg<br>might<br>million<br>miss<br>ml<br>more<br>moreover<br>most<br>mostly<br>mr<br>mrs<br>much<br>mug<br>must<br>my<br>myself<br>n<br>na<br>name<br>namely<br>nay<br>nd<br>near<br>nearly<br>necessarily<br>necessary<br>need<br>needs<br>neither<br>never<br>nevertheless<br>new<br>next<br>nine<br>ninety<br>no<br>nobody<br>non<br>none<br>nonetheless<br>noone<br>nor<br>normally<br>nos<br>not<br>noted<br>nothing<br>now<br>nowhere<br>o<br>obtain<br>obtained<br>n't<br>doesn<br>obviously<br>of<br>off<br>often<br>oh<br>ok<br>okay<br>old<br>omitted<br>on<br>once<br>one<br>ones<br>only<br>onto<br>or<br>ord<br>other<br>others<br>otherwise<br>ought<br>our<br>ours<br>ourselves<br>out<br>outside<br>over<br>overall<br>owing<br>own<br>p<br>page<br>pages<br>part<br>particular<br>particularly<br>past<br>per<br>perhaps<br>placed<br>please<br>plus<br>poorly<br>possible<br>possibly<br>potentially<br>pp<br>predominantly<br>present<br>previously<br>primarily<br>probably<br>promptly<br>proud<br>provides<br>put<br>q<br>que<br>quickly<br>quite<br>qv<br>r<br>ran<br>rather<br>rd<br>re<br>readily<br>really<br>recent<br>recently<br>ref<br>refs<br>regarding<br>regardless<br>regards<br>related<br>relatively<br>research<br>respectively<br>resulted<br>resulting<br>results<br>right<br>run<br>s<br>said<br>same<br>saw<br>say<br>saying<br>says<br>sec<br>section<br>see<br>seeing<br>seem<br>seemed<br>seeming<br>seems<br>seen<br>self<br>selves<br>sent<br>seven<br>several<br>shall<br>she<br>shed<br>she'll<br>shes<br>should<br>shouldn't<br>show<br>showed<br>shown<br>showns<br>shows<br>significant<br>significantly<br>similar<br>similarly<br>since<br>six<br>slightly<br>so<br>some<br>somebody<br>somehow<br>someone<br>somethan<br>something<br>sometime<br>sometimes<br>somewhat<br>somewhere<br>soon<br>sorry<br>specifically<br>specified<br>specify<br>specifying<br>still<br>stop<br>strongly<br>sub<br>substantially<br>successfully<br>such<br>sufficiently<br>suggest<br>sup<br>sure<br>t<br>take<br>taken<br>taking<br>tell<br>tends<br>th<br>than<br>thank<br>thanks<br>thanx<br>that<br>that'll<br>thats<br>that've<br>the<br>their<br>theirs<br>them<br>themselves<br>then<br>thence<br>there<br>thereafter<br>thereby<br>thered<br>therefore<br>therein<br>there'll<br>thereof<br>therere<br>theres<br>thereto<br>thereupon<br>there've<br>these<br>they<br>theyd<br>they'll<br>theyre<br>they've<br>think<br>this<br>those<br>thou<br>though<br>thoughh<br>thousand<br>throug<br>through<br>throughout<br>thru<br>thus<br>til<br>tip<br>to<br>together<br>too<br>took<br>toward<br>towards<br>tried<br>tries<br>truly<br>try<br>trying<br>ts<br>twice<br>two<br>u<br>un<br>under<br>unfortunately<br>unless<br>unlike<br>unlikely<br>until<br>unto<br>up<br>upon<br>ups<br>us<br>use<br>used<br>useful<br>usefully<br>usefulness<br>uses<br>using<br>usually<br>v<br>value<br>various<br>'ve<br>very<br>via<br>viz<br>vol<br>vols<br>vs<br>w<br>want<br>wants<br>was<br>wasnt<br>way<br>we<br>wed<br>welcome<br>we'll<br>went<br>were<br>werent<br>we've<br>what<br>whatever<br>what'll<br>whats<br>when<br>whence<br>whenever<br>where<br>whereafter<br>whereas<br>whereby<br>wherein<br>wheres<br>whereupon<br>wherever<br>whether<br>which<br>while<br>whim<br>whither<br>who<br>whod<br>whoever<br>whole<br>who'll<br>whom<br>whomever<br>whos<br>whose<br>why<br>widely<br>willing<br>wish<br>with<br>within<br>without<br>wont<br>words<br>world<br>would<br>wouldnt<br>www<br>x<br>y<br>yes<br>yet<br>you<br>youd<br>you'll<br>your<br>youre<br>yours<br>yourself<br>yourselves<br>you've<br>z<br>zero\"\n",
    "stopwords = long_list.split(\"<br>\")\n",
    "\n",
    "with open(\"finefoods.txt\") as f:\n",
    "    for line in f:\n",
    "        if (line.startswith(\"review/text:\")):           # The condition where we need the reviews.\n",
    "            separate_line=line.split(\"review/text: \")[1]     # To get the reviews sentence only.\n",
    "            reviews.append(separate_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the reviews.\n",
    "\n",
    "review_tokens=[nltk.word_tokenize(w) for w in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I',\n",
       "  'have',\n",
       "  'bought',\n",
       "  'several',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Vitality',\n",
       "  'canned',\n",
       "  'dog',\n",
       "  'food',\n",
       "  'products',\n",
       "  'and',\n",
       "  'have',\n",
       "  'found',\n",
       "  'them',\n",
       "  'all',\n",
       "  'to',\n",
       "  'be',\n",
       "  'of',\n",
       "  'good',\n",
       "  'quality',\n",
       "  '.',\n",
       "  'The',\n",
       "  'product',\n",
       "  'looks',\n",
       "  'more',\n",
       "  'like',\n",
       "  'a',\n",
       "  'stew',\n",
       "  'than',\n",
       "  'a',\n",
       "  'processed',\n",
       "  'meat',\n",
       "  'and',\n",
       "  'it',\n",
       "  'smells',\n",
       "  'better',\n",
       "  '.',\n",
       "  'My',\n",
       "  'Labrador',\n",
       "  'is',\n",
       "  'finicky',\n",
       "  'and',\n",
       "  'she',\n",
       "  'appreciates',\n",
       "  'this',\n",
       "  'product',\n",
       "  'better',\n",
       "  'than',\n",
       "  'most',\n",
       "  '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_tokens[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a list of lists we cannot use some basic functions from nltk to perform data cleaning so we create a new\n",
    "# 1 D list.\n",
    "\n",
    "token_list=[]\n",
    "for i in review_tokens:\n",
    "    for j in i:\n",
    "        token_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'have',\n",
       " 'bought',\n",
       " 'several',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Vitality',\n",
       " 'canned',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'products',\n",
       " 'and',\n",
       " 'have',\n",
       " 'found',\n",
       " 'them',\n",
       " 'all',\n",
       " 'to',\n",
       " 'be',\n",
       " 'of',\n",
       " 'good']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the words and alphabets removing every punctuation & special characters and converting everything to lower case.\n",
    "\n",
    "alpha_tokens=[w.lower() for w in token_list if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'have',\n",
       " 'bought',\n",
       " 'several',\n",
       " 'of',\n",
       " 'the',\n",
       " 'vitality',\n",
       " 'canned',\n",
       " 'dog',\n",
       " 'food']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defing the list L as per the instructions and filtering out the string br.\n",
    "\n",
    "L = list(set([word for word in alpha_tokens if word !=\"\" and word!= \"br\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miscegenation',\n",
       " 'overwater',\n",
       " 'unilateral',\n",
       " 'aren',\n",
       " 'shouldve',\n",
       " 'platablity',\n",
       " 'longneck',\n",
       " 'britan',\n",
       " 'brooken',\n",
       " 'toppins']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean list after removing the stopwords.\n",
    "\n",
    "W=[word for word in L if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miscegenation',\n",
       " 'overwater',\n",
       " 'unilateral',\n",
       " 'shouldve',\n",
       " 'platablity',\n",
       " 'longneck',\n",
       " 'britan',\n",
       " 'brooken',\n",
       " 'toppins',\n",
       " 'handbag']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the frequency distribution and the count of the top 500 words.\n",
    "\n",
    "freqDistribution = FreqDist(alpha_tokens)\n",
    "count = 0 \n",
    "top_words=[]\n",
    "top_words_count=[]\n",
    "\n",
    "for word, value in freqDistribution.most_common():\n",
    "    if(word in W):\n",
    "        top_words.append(word)\n",
    "        top_words_count.append(value)\n",
    "        count = count + 1\n",
    "        if(count == 500):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word - good            Count - 196971\n",
      "Word - taste            Count - 168126\n",
      "Word - great            Count - 165060\n",
      "Word - coffee            Count - 162628\n",
      "Word - product            Count - 148169\n",
      "Word - flavor            Count - 143785\n",
      "Word - tea            Count - 135147\n",
      "Word - love            Count - 127015\n",
      "Word - will            Count - 126793\n",
      "Word - food            Count - 124926\n",
      "Word - amazon            Count - 83082\n",
      "Word - time            Count - 81593\n",
      "Word - buy            Count - 76444\n",
      "Word - best            Count - 75827\n",
      "Word - price            Count - 74260\n",
      "Word - find            Count - 73226\n",
      "Word - well            Count - 69584\n",
      "Word - better            Count - 69368\n",
      "Word - dog            Count - 69060\n",
      "Word - eat            Count - 66937\n",
      "Word - water            Count - 59621\n",
      "Word - chocolate            Count - 59283\n",
      "Word - bag            Count - 56544\n",
      "Word - sugar            Count - 53103\n",
      "Word - cup            Count - 50915\n",
      "Word - drink            Count - 50294\n",
      "Word - sweet            Count - 50222\n",
      "Word - bought            Count - 49776\n",
      "Word - box            Count - 49220\n",
      "Word - day            Count - 46011\n",
      "Word - tastes            Count - 45342\n",
      "Word - store            Count - 44115\n",
      "Word - order            Count - 43422\n",
      "Word - bit            Count - 42607\n",
      "Word - recommend            Count - 42563\n",
      "Word - nice            Count - 41130\n",
      "Word - delicious            Count - 40493\n",
      "Word - favorite            Count - 39698\n",
      "Word - flavors            Count - 38452\n",
      "Word - mix            Count - 38379\n",
      "Word - free            Count - 37898\n",
      "Word - hot            Count - 37506\n",
      "Word - cat            Count - 37286\n",
      "Word - dogs            Count - 37274\n",
      "Word - brand            Count - 36955\n",
      "Word - stuff            Count - 36430\n",
      "Word - loves            Count - 36395\n",
      "Word - years            Count - 36040\n",
      "Word - treats            Count - 35672\n",
      "Word - lot            Count - 35509\n",
      "Word - add            Count - 35161\n",
      "Word - healthy            Count - 34787\n",
      "Word - chips            Count - 34414\n",
      "Word - ingredients            Count - 34311\n",
      "Word - organic            Count - 33871\n",
      "Word - quality            Count - 33694\n",
      "Word - milk            Count - 33525\n",
      "Word - small            Count - 33452\n",
      "Word - perfect            Count - 32446\n",
      "Word - ordered            Count - 32296\n",
      "Word - snack            Count - 31954\n",
      "Word - strong            Count - 31829\n",
      "Word - eating            Count - 31644\n",
      "Word - bad            Count - 31372\n",
      "Word - easy            Count - 30582\n",
      "Word - products            Count - 30318\n",
      "Word - green            Count - 29926\n",
      "Word - treat            Count - 29842\n",
      "Word - hard            Count - 29649\n",
      "Word - enjoy            Count - 29517\n",
      "Word - fresh            Count - 29432\n",
      "Word - salt            Count - 29396\n",
      "Word - long            Count - 29354\n",
      "Word - pack            Count - 29218\n",
      "Word - bags            Count - 29210\n",
      "Word - definitely            Count - 29182\n",
      "Word - buying            Count - 29130\n",
      "Word - oil            Count - 28766\n",
      "Word - regular            Count - 28699\n",
      "Word - thing            Count - 28602\n",
      "Word - thought            Count - 28526\n",
      "Word - cookies            Count - 28205\n",
      "Word - chicken            Count - 27785\n",
      "Word - high            Count - 27608\n",
      "Word - pretty            Count - 27520\n",
      "Word - natural            Count - 27276\n",
      "Word - local            Count - 27077\n",
      "Word - size            Count - 27047\n",
      "Word - work            Count - 27023\n",
      "Word - happy            Count - 26916\n",
      "Word - cats            Count - 26699\n",
      "Word - people            Count - 26193\n",
      "Word - big            Count - 26109\n",
      "Word - going            Count - 26030\n",
      "Word - package            Count - 25839\n",
      "Word - tasty            Count - 25353\n",
      "Word - diet            Count - 25146\n",
      "Word - shipping            Count - 24743\n",
      "Word - real            Count - 24421\n",
      "Word - sauce            Count - 24338\n",
      "Word - foods            Count - 24211\n",
      "Word - butter            Count - 24123\n",
      "Word - wonderful            Count - 23964\n",
      "Word - highly            Count - 23930\n",
      "Word - calories            Count - 23907\n",
      "Word - feel            Count - 23812\n",
      "Word - bars            Count - 23255\n",
      "Word - purchase            Count - 23198\n",
      "Word - tasted            Count - 23198\n",
      "Word - purchased            Count - 23181\n",
      "Word - dry            Count - 23111\n",
      "Word - excellent            Count - 22768\n",
      "Word - worth            Count - 22739\n",
      "Word - texture            Count - 22468\n",
      "Word - expensive            Count - 22019\n",
      "Word - year            Count - 21669\n",
      "Word - amount            Count - 21571\n",
      "Word - protein            Count - 21513\n",
      "Word - smell            Count - 21461\n",
      "Word - fat            Count - 21342\n",
      "Word - rice            Count - 21284\n",
      "Word - stores            Count - 21164\n",
      "Word - coconut            Count - 21130\n",
      "Word - tasting            Count - 21082\n",
      "Word - dark            Count - 21047\n",
      "Word - grocery            Count - 20707\n",
      "Word - half            Count - 20654\n",
      "Word - low            Count - 20458\n",
      "Word - kind            Count - 20444\n",
      "Word - morning            Count - 20407\n",
      "Word - things            Count - 20285\n",
      "Word - brands            Count - 20195\n",
      "Word - bottle            Count - 19965\n",
      "Word - vanilla            Count - 19953\n",
      "Word - fruit            Count - 19938\n",
      "Word - loved            Count - 19638\n",
      "Word - family            Count - 19520\n",
      "Word - received            Count - 19505\n",
      "Word - blend            Count - 19472\n",
      "Word - full            Count - 19448\n",
      "Word - days            Count - 19089\n",
      "Word - months            Count - 18909\n",
      "Word - problem            Count - 18811\n",
      "Word - reviews            Count - 18754\n",
      "Word - three            Count - 18746\n",
      "Word - cereal            Count - 18731\n",
      "Word - wo            Count - 18639\n",
      "Word - company            Count - 18637\n",
      "Word - case            Count - 18451\n",
      "Word - health            Count - 18266\n",
      "Word - candy            Count - 18179\n",
      "Word - black            Count - 18161\n",
      "Word - bar            Count - 18117\n",
      "Word - money            Count - 17558\n",
      "Word - light            Count - 17541\n",
      "Word - making            Count - 17524\n",
      "Word - flavored            Count - 17458\n",
      "Word - drinking            Count - 17376\n",
      "Word - review            Count - 17374\n",
      "Word - peanut            Count - 17316\n",
      "Word - large            Count - 17254\n",
      "Word - gluten            Count - 17078\n",
      "Word - arrived            Count - 17004\n",
      "Word - kids            Count - 16689\n",
      "Word - times            Count - 16615\n",
      "Word - top            Count - 16463\n",
      "Word - item            Count - 16432\n",
      "Word - husband            Count - 16361\n",
      "Word - bitter            Count - 16348\n",
      "Word - stars            Count - 16319\n",
      "Word - http            Count - 16306\n",
      "Word - variety            Count - 16282\n",
      "Word - disappointed            Count - 16135\n",
      "Word - extra            Count - 15992\n",
      "Word - corn            Count - 15968\n",
      "Word - beans            Count - 15875\n",
      "Word - fact            Count - 15870\n",
      "Word - packaging            Count - 15849\n",
      "Word - save            Count - 15732\n",
      "Word - decided            Count - 15677\n",
      "Word - cheese            Count - 15617\n",
      "Word - fine            Count - 15516\n",
      "Word - started            Count - 15492\n",
      "Word - honey            Count - 15470\n",
      "Word - boxes            Count - 15453\n",
      "Word - absolutely            Count - 15443\n",
      "Word - teas            Count - 15266\n",
      "Word - prefer            Count - 15227\n",
      "Word - popcorn            Count - 15225\n",
      "Word - smooth            Count - 15131\n",
      "Word - recommended            Count - 15112\n",
      "Word - deal            Count - 15083\n",
      "Word - couple            Count - 14995\n",
      "Word - house            Count - 14946\n",
      "Word - oz            Count - 14897\n",
      "Word - energy            Count - 14839\n",
      "Word - cream            Count - 14643\n",
      "Word - works            Count - 14553\n",
      "Word - wanted            Count - 14542\n",
      "Word - cheaper            Count - 14474\n",
      "Word - breakfast            Count - 14412\n",
      "Word - cups            Count - 14383\n",
      "Word - minutes            Count - 14375\n",
      "Word - baby            Count - 14339\n",
      "Word - cost            Count - 14303\n",
      "Word - roast            Count - 14302\n",
      "Word - ago            Count - 14226\n",
      "Word - meal            Count - 14171\n",
      "Word - open            Count - 14144\n",
      "Word - read            Count - 13938\n",
      "Word - white            Count - 13888\n",
      "Word - syrup            Count - 13697\n",
      "Word - juice            Count - 13650\n",
      "Word - powder            Count - 13624\n",
      "Word - longer            Count - 13553\n",
      "Word - rich            Count - 13549\n",
      "Word - cans            Count - 13467\n",
      "Word - help            Count - 13371\n",
      "Word - bold            Count - 13234\n",
      "Word - meat            Count - 13141\n",
      "Word - bread            Count - 13139\n",
      "Word - ordering            Count - 13130\n",
      "Word - serving            Count - 13127\n",
      "Word - pieces            Count - 13040\n",
      "Word - red            Count - 13008\n",
      "Word - amazing            Count - 13005\n",
      "Word - soft            Count - 12868\n",
      "Word - keurig            Count - 12867\n",
      "Word - cookie            Count - 12808\n",
      "Word - month            Count - 12741\n",
      "Word - fast            Count - 12728\n",
      "Word - weight            Count - 12462\n",
      "Word - week            Count - 12358\n",
      "Word - spicy            Count - 12233\n",
      "Word - glad            Count - 12210\n",
      "Word - fan            Count - 12208\n",
      "Word - quick            Count - 12102\n",
      "Word - soup            Count - 12095\n",
      "Word - side            Count - 12040\n",
      "Word - second            Count - 11954\n",
      "Word - mouth            Count - 11838\n",
      "Word - likes            Count - 11703\n",
      "Word - plastic            Count - 11487\n",
      "Word - son            Count - 11460\n",
      "Word - starbucks            Count - 11425\n",
      "Word - pasta            Count - 11404\n",
      "Word - gift            Count - 11384\n",
      "Word - difference            Count - 11355\n",
      "Word - beef            Count - 11306\n",
      "Word - ginger            Count - 11263\n",
      "Word - hair            Count - 11217\n",
      "Word - cinnamon            Count - 11184\n",
      "Word - crunchy            Count - 10982\n",
      "Word - friends            Count - 10976\n",
      "Word - potato            Count - 10901\n",
      "Word - mixed            Count - 10901\n",
      "Word - opened            Count - 10891\n",
      "Word - wheat            Count - 10854\n",
      "Word - problems            Count - 10824\n",
      "Word - jerky            Count - 10773\n",
      "Word - feed            Count - 10765\n",
      "Word - type            Count - 10762\n",
      "Word - canned            Count - 10742\n",
      "Word - ice            Count - 10727\n",
      "Word - brew            Count - 10718\n",
      "Word - life            Count - 10663\n",
      "Word - cold            Count - 10652\n",
      "Word - dried            Count - 10546\n",
      "Word - market            Count - 10492\n",
      "Word - online            Count - 10489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word - reason            Count - 10454\n",
      "Word - version            Count - 10387\n",
      "Word - teeth            Count - 10370\n",
      "Word - pet            Count - 10326\n",
      "Word - easily            Count - 10277\n",
      "Word - super            Count - 10247\n",
      "Word - nuts            Count - 10226\n",
      "Word - enjoyed            Count - 10178\n",
      "Word - chew            Count - 10169\n",
      "Word - fiber            Count - 10153\n",
      "Word - weeks            Count - 10145\n",
      "Word - artificial            Count - 10127\n",
      "Word - care            Count - 10123\n",
      "Word - formula            Count - 10096\n",
      "Word - start            Count - 10094\n",
      "Word - container            Count - 10078\n",
      "Word - brown            Count - 10049\n",
      "Word - salty            Count - 10049\n",
      "Word - cooking            Count - 10033\n",
      "Word - smaller            Count - 10026\n",
      "Word - machine            Count - 10011\n",
      "Word - cut            Count - 9973\n",
      "Word - daughter            Count - 9971\n",
      "Word - left            Count - 9956\n",
      "Word - guess            Count - 9927\n",
      "Word - yummy            Count - 9924\n",
      "Word - french            Count - 9914\n",
      "Word - snacks            Count - 9816\n",
      "Word - soy            Count - 9802\n",
      "Word - vet            Count - 9684\n",
      "Word - course            Count - 9671\n",
      "Word - drinks            Count - 9662\n",
      "Word - plain            Count - 9651\n",
      "Word - place            Count - 9648\n",
      "Word - blue            Count - 9629\n",
      "Word - recipe            Count - 9598\n",
      "Word - awesome            Count - 9550\n",
      "Word - exactly            Count - 9539\n",
      "Word - ingredient            Count - 9524\n",
      "Word - night            Count - 9498\n",
      "Word - bowl            Count - 9486\n",
      "Word - choice            Count - 9425\n",
      "Word - spice            Count - 9378\n",
      "Word - wife            Count - 9376\n",
      "Word - coffees            Count - 9368\n",
      "Word - oatmeal            Count - 9352\n",
      "Word - clean            Count - 9345\n",
      "Word - alternative            Count - 9326\n",
      "Word - single            Count - 9324\n",
      "Word - lemon            Count - 9282\n",
      "Word - original            Count - 9259\n",
      "Word - daily            Count - 9250\n",
      "Word - surprised            Count - 9174\n",
      "Word - simply            Count - 9146\n",
      "Word - aroma            Count - 9125\n",
      "Word - cocoa            Count - 9115\n",
      "Word - pleased            Count - 9097\n",
      "Word - crackers            Count - 9084\n",
      "Word - wrong            Count - 9080\n",
      "Word - pay            Count - 9061\n",
      "Word - special            Count - 9049\n",
      "Word - ate            Count - 9045\n",
      "Word - decaf            Count - 9045\n",
      "Word - flour            Count - 9008\n",
      "Word - aftertaste            Count - 8965\n",
      "Word - smells            Count - 8948\n",
      "Word - hand            Count - 8948\n",
      "Word - sodium            Count - 8941\n",
      "Word - list            Count - 8932\n",
      "Word - compared            Count - 8924\n",
      "Word - friend            Count - 8871\n",
      "Word - pods            Count - 8866\n",
      "Word - color            Count - 8861\n",
      "Word - body            Count - 8858\n",
      "Word - cook            Count - 8848\n",
      "Word - caffeine            Count - 8843\n",
      "Word - almonds            Count - 8781\n",
      "Word - finally            Count - 8775\n",
      "Word - close            Count - 8772\n",
      "Word - picky            Count - 8762\n",
      "Word - inside            Count - 8721\n",
      "Word - mild            Count - 8712\n",
      "Word - jar            Count - 8704\n",
      "Word - subscribe            Count - 8700\n",
      "Word - huge            Count - 8698\n",
      "Word - hope            Count - 8662\n",
      "Word - heat            Count - 8631\n",
      "Word - experience            Count - 8614\n",
      "Word - change            Count - 8611\n",
      "Word - noticed            Count - 8603\n",
      "Word - feeding            Count - 8596\n",
      "Word - ground            Count - 8553\n",
      "Word - hours            Count - 8547\n",
      "Word - flavorful            Count - 8523\n",
      "Word - looked            Count - 8520\n",
      "Word - chip            Count - 8517\n",
      "Word - stick            Count - 8511\n",
      "Word - stomach            Count - 8504\n",
      "Word - apple            Count - 8494\n",
      "Word - pepper            Count - 8386\n",
      "Word - service            Count - 8374\n",
      "Word - idea            Count - 8368\n",
      "Word - helps            Count - 8352\n",
      "Word - orange            Count - 8304\n",
      "Word - live            Count - 8286\n",
      "Word - packs            Count - 8264\n",
      "Word - needed            Count - 8207\n",
      "Word - fish            Count - 8167\n",
      "Word - soda            Count - 8148\n",
      "Word - cake            Count - 8137\n",
      "Word - delivery            Count - 8126\n",
      "Word - expected            Count - 8125\n",
      "Word - adding            Count - 8102\n",
      "Word - gum            Count - 8065\n",
      "Word - leave            Count - 8064\n",
      "Word - bite            Count - 8061\n",
      "Word - lots            Count - 8054\n",
      "Word - larger            Count - 8020\n",
      "Word - espresso            Count - 7980\n",
      "Word - leaves            Count - 7947\n",
      "Word - instant            Count - 7944\n",
      "Word - bottles            Count - 7910\n",
      "Word - completely            Count - 7909\n",
      "Word - star            Count - 7875\n",
      "Word - seeds            Count - 7851\n",
      "Word - bulk            Count - 7828\n",
      "Word - raw            Count - 7810\n",
      "Word - convenient            Count - 7808\n",
      "Word - continue            Count - 7807\n",
      "Word - noodles            Count - 7792\n",
      "Word - fantastic            Count - 7788\n",
      "Word - grain            Count - 7769\n",
      "Word - skin            Count - 7768\n",
      "Word - iced            Count - 7751\n",
      "Word - bottom            Count - 7731\n",
      "Word - medium            Count - 7726\n",
      "Word - takes            Count - 7724\n",
      "Word - weak            Count - 7665\n",
      "Word - cheap            Count - 7657\n",
      "Word - extremely            Count - 7562\n",
      "Word - packaged            Count - 7539\n",
      "Word - mind            Count - 7524\n",
      "Word - expect            Count - 7501\n",
      "Word - rest            Count - 7500\n",
      "Word - eaten            Count - 7453\n",
      "Word - mine            Count - 7440\n",
      "Word - label            Count - 7411\n",
      "Word - chewy            Count - 7387\n",
      "Word - pot            Count - 7387\n",
      "Word - wellness            Count - 7381\n",
      "Word - packages            Count - 7378\n",
      "Word - healthier            Count - 7376\n",
      "Word - shipped            Count - 7345\n",
      "Word - excited            Count - 7294\n",
      "Word - stock            Count - 7284\n",
      "Word - chai            Count - 7280\n",
      "Word - ounce            Count - 7275\n",
      "Word - granola            Count - 7245\n",
      "Word - told            Count - 7242\n",
      "Word - true            Count - 7235\n",
      "Word - based            Count - 7208\n",
      "Word - glass            Count - 7192\n",
      "Word - filling            Count - 7143\n",
      "Word - waste            Count - 7142\n",
      "Word - issues            Count - 7137\n",
      "Word - packets            Count - 7134\n",
      "Word - sold            Count - 7126\n",
      "Word - maker            Count - 7123\n",
      "Word - grams            Count - 7080\n",
      "Word - items            Count - 7037\n",
      "Word - normal            Count - 7033\n",
      "Word - entire            Count - 7006\n",
      "Word - crunch            Count - 6938\n",
      "Word - note            Count - 6936\n",
      "Word - opinion            Count - 6905\n",
      "Word - packet            Count - 6892\n",
      "Word - carry            Count - 6864\n",
      "Word - thick            Count - 6853\n",
      "Word - point            Count - 6833\n",
      "Word - calorie            Count - 6832\n",
      "Word - eats            Count - 6817\n",
      "Word - wait            Count - 6806\n",
      "Word - called            Count - 6756\n",
      "Word - content            Count - 6754\n",
      "Word - pound            Count - 6746\n",
      "Word - today            Count - 6720\n",
      "Word - sweetness            Count - 6719\n",
      "Word - hint            Count - 6698\n",
      "Word - purchasing            Count - 6693\n",
      "Word - almond            Count - 6686\n",
      "Word - puppy            Count - 6678\n",
      "Word - baking            Count - 6606\n",
      "Word - mountain            Count - 6570\n",
      "Word - liquid            Count - 6563\n",
      "Word - lunch            Count - 6562\n",
      "Word - olive            Count - 6515\n",
      "Word - stash            Count - 6509\n",
      "Word - reading            Count - 6504\n",
      "Word - bean            Count - 6497\n",
      "Word - easier            Count - 6457\n",
      "Word - break            Count - 6423\n",
      "Word - vitamin            Count - 6419\n",
      "Word - creamy            Count - 6413\n",
      "Word - difficult            Count - 6389\n",
      "Word - christmas            Count - 6381\n",
      "Word - pop            Count - 6374\n",
      "Word - pure            Count - 6367\n",
      "Word - delivered            Count - 6364\n",
      "Word - tiny            Count - 6345\n",
      "Word - dinner            Count - 6319\n",
      "Word - sale            Count - 6275\n",
      "Word - decent            Count - 6248\n",
      "Word - benefits            Count - 6242\n",
      "Word - stopped            Count - 6228\n",
      "Word - customer            Count - 6160\n",
      "Word - mint            Count - 6158\n",
      "Word - worked            Count - 6109\n",
      "Word - lower            Count - 6105\n",
      "Word - varieties            Count - 6087\n",
      "Word - loose            Count - 6078\n",
      "Word - batch            Count - 6067\n",
      "Word - licorice            Count - 6052\n",
      "Word - consistency            Count - 6049\n",
      "Word - remember            Count - 6043\n",
      "Word - sweetener            Count - 6043\n",
      "Word - addition            Count - 5998\n",
      "Word - tuna            Count - 5995\n",
      "Word - total            Count - 5986\n",
      "Word - stay            Count - 5977\n",
      "Word - discovered            Count - 5977\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,500):\n",
    "    print(\"Word -\",top_words[i],\" \"*10,\"Count -\",top_words_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the the reviews according to the top 500 words.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary = top_words)\n",
    "X = vectorizer.fit_transform(reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A KMeans clustering model with 10 clusters fitted on the transformed data (vectors).\n",
    "kmeans = KMeans(n_clusters=10).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9,  42,  90, ..., 425, 146, 244],\n",
       "       [ 18,  48,  43, ..., 244, 264, 186],\n",
       "       [  0,   1,   5, ..., 273, 419, 146],\n",
       "       ...,\n",
       "       [ 21, 124,   1, ..., 460, 299, 146],\n",
       "       [  2,   1,   7, ..., 170, 419, 146],\n",
       "       [ 52, 254,  22, ..., 314, 419, 205]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting the cluster centers from 1 to 10.\n",
    "\n",
    "cluster_center_sorted = kmeans.cluster_centers_.argsort()[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the list of top 5 words from every cluster with the respective feature values.\n",
    "\n",
    "final_words = []\n",
    "final_feature_vals = []\n",
    "\n",
    "for i in range(len(cluster_center_sorted)):\n",
    "    \n",
    "    word_list = []\n",
    "    feature_list = []\n",
    "    \n",
    "    for word in list(cluster_center_sorted[i, :5]):\n",
    "        \n",
    "        word_list.append(top_words[word])\n",
    "        feature_list.append(kmeans.cluster_centers_[i,word])\n",
    "        \n",
    "    final_words.append(word_list)\n",
    "    final_feature_vals.append(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 1\n",
      "['food', 'cat', 'cats', 'eat', 'dry']\n",
      "[0.3044970295398982, 0.1953652692876704, 0.13589068856981512, 0.058729111058650266, 0.04129105265532189]\n",
      "\n",
      "Cluster 2\n",
      "['dog', 'treats', 'dogs', 'loves', 'treat']\n",
      "[0.2882745826967321, 0.16081202587721652, 0.13988634359155955, 0.07525221677228114, 0.07502001824901054]\n",
      "\n",
      "Cluster 3\n",
      "['good', 'taste', 'flavor', 'love', 'will']\n",
      "[0.04793710374192966, 0.04346368952295359, 0.037065479291557395, 0.031172750944131675, 0.028458138485433743]\n",
      "\n",
      "Cluster 4\n",
      "['amazon', 'price', 'find', 'store', 'stores']\n",
      "[0.13273911196084875, 0.08760844830480495, 0.08656834415186411, 0.07455397165040865, 0.05537561543790783]\n",
      "\n",
      "Cluster 5\n",
      "['tea', 'green', 'teas', 'flavor', 'drink']\n",
      "[0.4622750816275693, 0.06272519896744917, 0.05755728159737811, 0.04779807878852323, 0.044159246930958546]\n",
      "\n",
      "Cluster 6\n",
      "['coffee', 'cup', 'flavor', 'strong', 'cups']\n",
      "[0.3863167390618253, 0.09699027237673293, 0.05160615830511522, 0.05153176023621414, 0.050972046255917496]\n",
      "\n",
      "Cluster 7\n",
      "['product', 'good', 'great', 'will', 'taste']\n",
      "[0.2535641348100077, 0.045639982193274684, 0.04311350737031022, 0.03632334354022749, 0.031531316331920405]\n",
      "\n",
      "Cluster 8\n",
      "['chocolate', 'dark', 'taste', 'cookies', 'bar']\n",
      "[0.35263244195518445, 0.057676141831388694, 0.04867290729579888, 0.04806215749337736, 0.044798385516740744]\n",
      "\n",
      "Cluster 9\n",
      "['great', 'taste', 'love', 'snack', 'flavor']\n",
      "[0.2332531467284691, 0.04801324772605916, 0.044639731631405354, 0.038058293074585824, 0.037392858480076625]\n",
      "\n",
      "Cluster 10\n",
      "['chips', 'potato', 'bag', 'salt', 'chip']\n",
      "[0.4292077460661139, 0.08456933050239891, 0.06600822670371803, 0.06026650362209394, 0.05959347613338446]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(\"\\nCluster \"+str(i+1))\n",
    "    print(final_words[i]) \n",
    "    print(final_feature_vals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
