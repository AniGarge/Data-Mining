{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"foods.txt\"\n",
    "outputFile = \"newFineFoods.csv\"\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import re\n",
    "\n",
    "def removeChar(sentence):\n",
    "    sentence = sentence.lower()                             #Changing sentence to lowercase\n",
    "    clean = re.compile('<.*?>')\n",
    "    sentence = re.sub(clean, ' ', sentence)        \n",
    "    sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)        \n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "local = []\n",
    "finalVal = []\n",
    "\n",
    "file = open(inputFile, encoding='latin-1')\n",
    "outfile = open(outputFile,\"w\")\n",
    "\n",
    "currLine = []\n",
    "for line in file:\n",
    "   line = line.strip()\n",
    "   if line == \"\": \n",
    "      outfile.write(\",\".join(currLine))\n",
    "      outfile.write(\"\\n\")\n",
    "      currLine = []\n",
    "      continue\n",
    "   parts = line.split(\":\",1)\n",
    "\n",
    "   if 'review/text' in parts[0]:\n",
    "      local = removeChar(parts[-1])\n",
    "      currLine.append(local)\n",
    "    \n",
    "      finalVal.append(local)\n",
    "\n",
    "if currLine != []:\n",
    "    outfile.write(\",\".join(currLine))\n",
    "\n",
    "file.close()\n",
    "outfile.close()\n",
    "\n",
    "breakWords = \"a<br>able<br>about<br>above<br>abst<br>accordance<br>according<br>accordingly<br>across<br>act<br>actually<br>added<br>adj<br>affected<br>affecting<br>affects<br>after<br>afterwards<br>again<br>against<br>ah<br>all<br>almost<br>alone<br>along<br>already<br>also<br>although<br>always<br>am<br>among<br>amongst<br>an<br>and<br>announce<br>another<br>any<br>anybody<br>anyhow<br>anymore<br>anyone<br>anything<br>anyway<br>anyways<br>anywhere<br>apparently<br>approximately<br>are<br>aren<br>arent<br>arise<br>around<br>as<br>aside<br>ask<br>asking<br>at<br>auth<br>available<br>away<br>awfully<br>b<br>back<br>be<br>became<br>because<br>become<br>becomes<br>becoming<br>been<br>before<br>beforehand<br>begin<br>beginning<br>beginnings<br>begins<br>behind<br>being<br>believe<br>below<br>beside<br>besides<br>between<br>beyond<br>biol<br>both<br>brief<br>briefly<br>but<br>by<br>c<br>ca<br>came<br>can<br>cannot<br>can't<br>cause<br>causes<br>certain<br>certainly<br>co<br>com<br>come<br>comes<br>contain<br>containing<br>contains<br>could<br>couldnt<br>d<br>date<br>did<br>didn't<br>different<br>do<br>does<br>doesn't<br>doing<br>done<br>don't<br>down<br>downwards<br>due<br>during<br>e<br>each<br>ed<br>edu<br>effect<br>eg<br>eight<br>eighty<br>either<br>else<br>elsewhere<br>end<br>ending<br>enough<br>especially<br>et<br>et-al<br>etc<br>even<br>ever<br>every<br>everybody<br>everyone<br>everything<br>everywhere<br>ex<br>except<br>f<br>far<br>few<br>ff<br>fifth<br>first<br>five<br>fix<br>followed<br>following<br>follows<br>for<br>former<br>formerly<br>forth<br>found<br>four<br>from<br>further<br>furthermore<br>g<br>gave<br>get<br>gets<br>getting<br>give<br>given<br>gives<br>giving<br>go<br>goes<br>gone<br>got<br>gotten<br>h<br>had<br>happens<br>hardly<br>has<br>hasn't<br>have<br>haven't<br>having<br>he<br>hed<br>hence<br>her<br>here<br>hereafter<br>hereby<br>herein<br>heres<br>hereupon<br>hers<br>herself<br>hes<br>hi<br>hid<br>him<br>himself<br>his<br>hither<br>home<br>how<br>howbeit<br>however<br>hundred<br>i<br>id<br>ie<br>if<br>i'll<br>im<br>immediate<br>immediately<br>importance<br>important<br>in<br>inc<br>indeed<br>index<br>information<br>instead<br>into<br>invention<br>inward<br>is<br>isn't<br>it<br>itd<br>it'll<br>its<br>itself<br>i've<br>j<br>just<br>k<br>keep<br>keeps<br>kept<br>kg<br>km<br>know<br>known<br>knows<br>l<br>largely<br>last<br>lately<br>later<br>latter<br>latterly<br>least<br>less<br>lest<br>let<br>lets<br>like<br>liked<br>likely<br>line<br>little<br>'ll<br>look<br>looking<br>looks<br>ltd<br>m<br>made<br>mainly<br>make<br>makes<br>many<br>may<br>maybe<br>me<br>mean<br>means<br>meantime<br>meanwhile<br>merely<br>mg<br>might<br>million<br>miss<br>ml<br>more<br>moreover<br>most<br>mostly<br>mr<br>mrs<br>much<br>mug<br>must<br>my<br>myself<br>n<br>na<br>name<br>namely<br>nay<br>nd<br>near<br>nearly<br>necessarily<br>necessary<br>need<br>needs<br>neither<br>never<br>nevertheless<br>new<br>next<br>nine<br>ninety<br>no<br>nobody<br>non<br>none<br>nonetheless<br>noone<br>nor<br>normally<br>nos<br>not<br>noted<br>nothing<br>now<br>nowhere<br>o<br>obtain<br>obtained<br>obviously<br>of<br>off<br>often<br>oh<br>ok<br>okay<br>old<br>omitted<br>on<br>once<br>one<br>ones<br>only<br>onto<br>or<br>ord<br>other<br>others<br>otherwise<br>ought<br>our<br>ours<br>ourselves<br>out<br>outside<br>over<br>overall<br>owing<br>own<br>p<br>page<br>pages<br>part<br>particular<br>particularly<br>past<br>per<br>perhaps<br>placed<br>please<br>plus<br>poorly<br>possible<br>possibly<br>potentially<br>pp<br>predominantly<br>present<br>previously<br>primarily<br>probably<br>promptly<br>proud<br>provides<br>put<br>q<br>que<br>quickly<br>quite<br>qv<br>r<br>ran<br>rather<br>rd<br>re<br>readily<br>really<br>recent<br>recently<br>ref<br>refs<br>regarding<br>regardless<br>regards<br>related<br>relatively<br>research<br>respectively<br>resulted<br>resulting<br>results<br>right<br>run<br>s<br>said<br>same<br>saw<br>say<br>saying<br>says<br>sec<br>section<br>see<br>seeing<br>seem<br>seemed<br>seeming<br>seems<br>seen<br>self<br>selves<br>sent<br>seven<br>several<br>shall<br>she<br>shed<br>she'll<br>shes<br>should<br>shouldn't<br>show<br>showed<br>shown<br>showns<br>shows<br>significant<br>significantly<br>similar<br>similarly<br>since<br>six<br>slightly<br>so<br>some<br>somebody<br>somehow<br>someone<br>somethan<br>something<br>sometime<br>sometimes<br>somewhat<br>somewhere<br>soon<br>sorry<br>specifically<br>specified<br>specify<br>specifying<br>still<br>stop<br>strongly<br>sub<br>substantially<br>successfully<br>such<br>sufficiently<br>suggest<br>sup<br>sure<br>t<br>take<br>taken<br>taking<br>tell<br>tends<br>th<br>than<br>thank<br>thanks<br>thanx<br>that<br>that'll<br>thats<br>that've<br>the<br>their<br>theirs<br>them<br>themselves<br>then<br>thence<br>there<br>thereafter<br>thereby<br>thered<br>therefore<br>therein<br>there'll<br>thereof<br>therere<br>theres<br>thereto<br>thereupon<br>there've<br>these<br>they<br>theyd<br>they'll<br>theyre<br>they've<br>think<br>this<br>those<br>thou<br>though<br>thoughh<br>thousand<br>throug<br>through<br>throughout<br>thru<br>thus<br>til<br>tip<br>to<br>together<br>too<br>took<br>toward<br>towards<br>tried<br>tries<br>truly<br>try<br>trying<br>ts<br>twice<br>two<br>u<br>un<br>under<br>unfortunately<br>unless<br>unlike<br>unlikely<br>until<br>unto<br>up<br>upon<br>ups<br>us<br>use<br>used<br>useful<br>usefully<br>usefulness<br>uses<br>using<br>usually<br>v<br>value<br>various<br>'ve<br>very<br>via<br>viz<br>vol<br>vols<br>vs<br>w<br>want<br>wants<br>was<br>wasnt<br>way<br>we<br>wed<br>welcome<br>we'll<br>went<br>were<br>werent<br>we've<br>what<br>whatever<br>what'll<br>whats<br>when<br>whence<br>whenever<br>where<br>whereafter<br>whereas<br>whereby<br>wherein<br>wheres<br>whereupon<br>wherever<br>whether<br>which<br>while<br>whim<br>whither<br>who<br>whod<br>whoever<br>whole<br>who'll<br>whom<br>whomever<br>whos<br>whose<br>why<br>widely<br>willing<br>wish<br>with<br>within<br>without<br>wont<br>words<br>world<br>would<br>wouldnt<br>www<br>x<br>y<br>yes<br>yet<br>you<br>youd<br>you'll<br>your<br>youre<br>yours<br>yourself<br>yourselves<br>you've<br>z<br>zero\"\n",
    "breakWordslist = breakWords.split(\"<br>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i have done a lot of research to find the best food for my cat  and this is an excellent food   that is also according to my holistic veterinarian   they put probiotics on the kibble as the last step  which is very important to me   the best thing is that my cat loved it immediately and i had to stop mixing it with the old food because she only would eat holistic select \n"
     ]
    }
   ],
   "source": [
    "print(finalVal[120])\n",
    "\n",
    "import nltk\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string \n",
    "\n",
    "ps = nltk.WordNetLemmatizer()  \n",
    "\n",
    "con = lambda x: ps.lemmatize(str.strip(x, string.punctuation + \"0123456789\").lower())\n",
    "reviewList = list(map(con, nltk.tokenize.regexp.wordpunct_tokenize(\" \".join(finalVal))))\n",
    "\n",
    "#print(reviewList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakWordslist = list(map(con, breakWordslist))\n",
    "L = list(set([w for w in reviewList if w !=\"\" and w!= \"br\" and not w.isnumeric()]))\n",
    "W = [w for w in L if w not in breakWordslist]\n",
    "        \n",
    "wrdCount = nltk.FreqDist(reviewList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "startWords = []\n",
    "\n",
    "for k, value in wrdCount.most_common():\n",
    "    if(k in W):\n",
    "        startWords.append(k)\n",
    "        count+=1\n",
    "        \n",
    "        if(count == 500):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary = startWords)\n",
    "X = vectorizer.fit_transform(finalVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['product', 'good', 'great', 'will', 'taste'], ['good', 'taste', 'flavor', 'love', 'will'], ['tea', 'green', 'flavor', 'drink', 'good'], ['gluten', 'free', 'good', 'sugar', 'taste'], ['coffee', 'cup', 'strong', 'flavor', 'good'], ['great', 'taste', 'love', 'snack', 'flavor'], ['chocolate', 'dark', 'taste', 'hot', 'good'], ['food', 'cat', 'eat', 'dry', 'love'], ['amazon', 'price', 'find', 'store', 'local'], ['dog', 'food', 'treat', 'will', 'product']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 10, random_state = 0).fit(X)\n",
    "t = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "out = []\n",
    "for i in range(len(t)):\n",
    "    tList = []\n",
    "    for ind in list(t[i, :5]):\n",
    "        tList.append(startWords[ind])\n",
    "    out.append(tList)\n",
    "print(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
